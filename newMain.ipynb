{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703f5ac-8810-4d55-b889-8e082890297f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing libs and enabling auto reload on notebooks.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.special import expit\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def haversine_distance(row):\n",
    "    # Calculate the Haversine distance between two points in kilometers (using latitude and longitude)\n",
    "    lon1, lat1, lon2, lat2 = map(math.radians,\n",
    "                                 [row['latitude'], row['longitude'], row['merchLatitude'], row['merchLongitude']])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    r = 6371  # Radius of Earth in kilometers\n",
    "    distance = r * c\n",
    "    return distance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa285db0ae63c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13c9444-a077-45ec-bc0a-c71bbcac73f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading data training set provided\n",
    "df = pd.read_csv(\"trainData.csv\")\n",
    "df.dropna(inplace=True)\n",
    "df.drop(\n",
    "    columns=[\"firstName\", \"lastName\", \"street\", \"zip\", \"job\", \"cityPop\", \"transNum\", \"city\", \"state\", \"creditCardNum\",\n",
    "             \"business\"], inplace=True)\n",
    "df['dateOfBirth'] = pd.to_datetime(df['dateOfBirth'])\n",
    "df['dateOfBirth'] = df['dateOfBirth'].dt.year.astype(float)\n",
    "\n",
    "column_index = df.columns.get_loc(\"isFraud\")\n",
    "df.insert(column_index, \"amount^2\", df[\"amount\"] ** 2)\n",
    "\n",
    "# Mapping gender to numbers so that we can use them in our features\n",
    "gender_map = {'M': 2.0, 'F': 1.0}\n",
    "df['gender'] = df['gender'].map(gender_map)\n",
    "\n",
    "# Turning the unixTime col into the distance_km col (unix time was wrong in og dataset)\n",
    "df['unixTime'] = df.apply(haversine_distance, axis=1)\n",
    "df.rename(columns={'unixTime': 'distance_km'}, inplace=True)\n",
    "\n",
    "# Mapping all of the cats to a number\n",
    "cat_map = {\n",
    "    'misc_net': 10,\n",
    "    'shopping_net': 9,\n",
    "    'misc_pos': 8,\n",
    "    'grocery_pos': 7,\n",
    "    'entertainment': 6,\n",
    "    'gas_transport': 5,\n",
    "    'personal_care': 4,\n",
    "    'shopping_pos': 3,\n",
    "    'food_dining': 2,\n",
    "    'home': 1,\n",
    "    'kids_pets': 1,\n",
    "    'grocery_net': 2,\n",
    "    'health_fitness': 3,\n",
    "    'travel': 4\n",
    "}\n",
    "\n",
    "# Converting transDate to give the date in unix time and then normalize the data\n",
    "df['transDate'] = pd.to_datetime(df['transDate'], format='%Y-%m-%d %H:%M')\n",
    "df['transDate'] = df['transDate'].apply(lambda x: datetime.timestamp(x))\n",
    "df['transDate'] = df['transDate'] / 1000000000\n",
    "\n",
    "# Map the categories to their numerical values\n",
    "df['category'] = df['category'].map(cat_map)\n",
    "\n",
    "# Droping the columns we used since we dont need them anymore\n",
    "df.drop(columns=['latitude', 'longitude', 'merchLatitude', 'merchLongitude'], inplace=True)\n",
    "\n",
    "# Ensuring all data types are float64\n",
    "df = df.astype(float)\n",
    "\n",
    "# Converting dataframe to csv\n",
    "df.to_csv(\"cleanedDataTrain.csv\", index=False)\n",
    "\n",
    "# Write dataFrame to a .txt file\n",
    "with open('cleanedDataTrain.txt', 'w') as f:\n",
    "    for index, row in df.iterrows():\n",
    "        f.write(\n",
    "            f\"{row['transDate']},{row['category']},{row['amount']},{row['gender']},{row['dateOfBirth']},{row['distance_km']},{row['amount^2']},{row['isFraud']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1e541-7fb5-45c8-b96d-53fb475a083f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading data in numpy\n",
    "def load_data(filename, testing):\n",
    "    data = np.loadtxt(filename, delimiter=',', skiprows=1)\n",
    "    if testing:\n",
    "        X = data[:, :-1]\n",
    "        y = data[:, -1]\n",
    "        return X, y\n",
    "    X = data[:, :]\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8258d5ce-7c2e-457c-b941-222a4271add3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting the features and the output var\n",
    "X_train, y_train = load_data(\"cleanedDataTrain.txt\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e037c18-b4d8-4fab-ad42-10bb16e8d89e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # print(\"test3\")\n",
    "    #  if isinstance(z, int) or isinstance(z, float):\n",
    "    #      return logistic_function(z)\n",
    "    # \n",
    "    #  return logistic_function(z)\n",
    "\n",
    "    #if isinstance(z, int) or isinstance(z, float):\n",
    "    # return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    #return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    # def sigmoid(z):\n",
    "\n",
    "    # This equation still is correct for sigmoid however helps us avoid overflow errors\n",
    "    return 0.5 * (1 + np.tanh(0.5 * z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288ab55e-a0cf-4fb3-a716-241d57f0db9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b, *argv):\n",
    "    m, n = X.shape\n",
    "\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(m):\n",
    "        zwb = np.dot(w, X[i]) + b\n",
    "        fwb = sigmoid(zwb)\n",
    "\n",
    "        # Clip the values of fwb to avoid log(0) or log(1) issues\n",
    "        fwb = np.clip(fwb, 1e-15, 1 - 1e-15)\n",
    "\n",
    "        loss = (-y[i] * np.log(fwb)) - ((1 - y[i]) * np.log(1 - fwb))\n",
    "        total_cost += loss\n",
    "\n",
    "    total_cost = total_cost / m\n",
    "\n",
    "    return total_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1c137c-527f-4060-b31b-5bcf039a8ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Computing gradient\n",
    "def compute_gradient(X, y, w, b, *argv):\n",
    "    m, n = X.shape\n",
    "    dj_dw = np.zeros(w.shape)\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):\n",
    "        z_wb = np.dot(X[i], w) + b\n",
    "        f_wb = sigmoid(z_wb)\n",
    "\n",
    "        dj_db += f_wb - y[i]\n",
    "\n",
    "        dj_dw += (f_wb - y[i]) * X[i]\n",
    "\n",
    "    dj_dw /= m\n",
    "    dj_db /= m\n",
    "\n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eb0f5b-a2f7-4920-ba07-e3c8ded97825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gradient Descent\n",
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters, lambda_):\n",
    "    #  print(\"test6\")\n",
    "    m, n = X.shape\n",
    "\n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db, dj_dw = gradient_function(X, y, w_in, b_in, lambda_)\n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w_in = w_in - alpha * dj_dw\n",
    "        b_in = b_in - alpha * dj_db\n",
    "\n",
    "        # Save cost J at each iteration\n",
    "        if i < 100000:  # prevent resource exhaustion \n",
    "            cost = cost_function(X, y, w_in, b_in, lambda_)\n",
    "            J_history.append(cost)\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i % math.ceil(num_iters / 10) == 0 or i == (num_iters - 1):\n",
    "            w_history.append(w_in)\n",
    "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.5f}   \")\n",
    "\n",
    "    return w_in, b_in, J_history#, w_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a46313-aad5-4e5d-b235-1aa5e17aa994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "def predict(X, w, b, testing=True):\n",
    "    m, n = X.shape\n",
    "\n",
    "    p = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        zwb = np.dot(w, X[i]) + b\n",
    "        zwb = zwb / 30780000  # Divided by sample mean (could improve this :D)\n",
    "        fwb = sigmoid(zwb)\n",
    "        p[i] = fwb <= 0.40\n",
    "\n",
    "    # Last data value not working correctly just appending default value 0 (only needed for final dataset)\n",
    "    if not testing:\n",
    "        p = np.append(p, 0)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cost compute\n",
    "def compute_cost_reg(X, y, w, b, lambda_=1):\n",
    "    #print(\"test8\")\n",
    "    m, n = X.shape\n",
    "    cost_without_reg = compute_cost(X, y, w, b)\n",
    "    reg_cost = 0\n",
    "\n",
    "    zwb = np.dot(X, w) + b\n",
    "    fwb = sigmoid(zwb)\n",
    "\n",
    "    reg_cost = np.sum(w ** 2) * lambda_ / (2 * m)\n",
    "\n",
    "    total_cost = cost_without_reg + reg_cost\n",
    "\n",
    "    return total_cost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad5a8d619faf0569"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compute Gradient\n",
    "def compute_gradient_reg(X, y, w, b, lambda_=1):\n",
    "    # print(\"test9\")\n",
    "    m, n = X.shape\n",
    "\n",
    "    dj_db, dj_dw = compute_gradient(X, y, w, b)\n",
    "\n",
    "    for j in range(n):\n",
    "        dj_dw[j] = dj_dw[j] + (lambda_ / m) * w[j]\n",
    "\n",
    "    return dj_db, dj_dw"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9389f6a3172d820"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Testing (was trying to find correct lambda_ and alpha values\n",
    "np.random.seed(1)\n",
    "init_w = np.random.rand(X_train.shape[1]) - 0.5\n",
    "init_b = 1.0\n",
    "\n",
    "lambda_ = 0.01  # 0.01\n",
    "\n",
    "# Some gradient descent settings\n",
    "iterations = 1000\n",
    "alpha = 0.01  # 0.01\n",
    "w, b, J_history = gradient_descent(X_train, y_train, init_w, init_b,\n",
    "                                              compute_cost_reg, compute_gradient_reg,\n",
    "                                              alpha, iterations, lambda_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd716c52c313a3cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p = predict(X_train, w, b)\n",
    "print(f\"Train Accuracy: {np.mean(p == y_train) * 100}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "687fd322a6b277bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ploting our cost function (looks very wrong :/)\n",
    "def plot_cost_over_iterations(J_history):\n",
    "    plt.plot(range(len(J_history)), J_history, marker='o', linestyle='-')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Cost')\n",
    "    plt.title('Cost Function Over Iterations Train')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Assuming you have already called gradient_descent and obtained J_history\n",
    "plot_cost_over_iterations(J_history)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4890ffc767dc87b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Using a class and my own model because we can auto run iters to find the best lambda and alhpa vals\n",
    "class GradientDescentWrapper(BaseEstimator):\n",
    "    def __init__(self, alpha, lambda_, num_iters):\n",
    "        self.alpha = alpha\n",
    "        self.lambda_ = lambda_\n",
    "        self.num_iters = num_iters\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.w_, self.b_, self.J_history_ = gradient_descent(X, y, init_w, init_b, compute_cost_reg,\n",
    "                                                             compute_gradient_reg, self.alpha, self.num_iters,\n",
    "                                                             self.lambda_)\n",
    "        return self\n",
    "\n",
    "\n",
    "# Creating an instance of my wrapper class\n",
    "your_model = GradientDescentWrapper(alpha=0.01, lambda_=0.01, num_iters=20)  # 1000\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cb143b141fa057b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.05, 0.1, 0.5],  # Range of values for alpha\n",
    "    'lambda_': [0.001, 0.01, 0.1, 0.5, 1.0]  # Range of values for lambda\n",
    "}\n",
    "\n",
    "# cross-validation\n",
    "grid_search = GridSearchCV(estimator=your_model, param_grid=param_grid, cv=3,  #5\n",
    "                           scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56ef923165d1d25a"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "debd7ea9687aea53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Opening up the actual test dataset (renamed)\n",
    "# doing same thing as df1 (see comments there)\n",
    "df2 = pd.read_csv(\"team_9_og.csv\")\n",
    "df2.dropna(inplace=True)\n",
    "df2.drop(\n",
    "    columns=[\"firstName\", \"lastName\", \"street\", \"zip\", \"job\", \"cityPop\", \"transNum\", \"city\", \"state\", \"creditCardNum\",\n",
    "             \"business\"], inplace=True)\n",
    "df2['dateOfBirth'] = pd.to_datetime(df['dateOfBirth'])\n",
    "df2['dateOfBirth'] = df2['dateOfBirth'].dt.year.astype(float)\n",
    "\n",
    "df2[\"amount^2\"] = df[\"amount\"] ** 2\n",
    "\n",
    "gender_map = {'M': 2.0, 'F': 1.0}\n",
    "df2['gender'] = df2['gender'].map(gender_map)\n",
    "\n",
    "df2['unixTime'] = df2.apply(haversine_distance, axis=1)\n",
    "df2.rename(columns={'unixTime': 'distance_km'}, inplace=True)\n",
    "\n",
    "cat_map = {\n",
    "    'misc_net': 10,\n",
    "    'shopping_net': 9,\n",
    "    'misc_pos': 8,\n",
    "    'grocery_pos': 7,\n",
    "    'entertainment': 6,\n",
    "    'gas_transport': 5,\n",
    "    'personal_care': 4,\n",
    "    'shopping_pos': 3,\n",
    "    'food_dining': 2,\n",
    "    'home': 1,\n",
    "    'kids_pets': 1,\n",
    "    'grocery_net': 2,\n",
    "    'health_fitness': 3,\n",
    "    'travel': 4\n",
    "}\n",
    "\n",
    "df2['transDate'] = pd.to_datetime(df2['transDate'], format='%Y-%m-%d %H:%M')\n",
    "df2['transDate'] = df2['transDate'].apply(lambda x: datetime.timestamp(x))\n",
    "df2['transDate'] = df2['transDate'] / 1000000000\n",
    "\n",
    "df2['category'] = df2['category'].map(cat_map)\n",
    "\n",
    "df2.drop(columns=['latitude', 'longitude', 'merchLatitude', 'merchLongitude'], inplace=True)\n",
    "\n",
    "df2 = df2.astype(float)\n",
    "\n",
    "# Sending cleaned df to a csv file\n",
    "df2.to_csv(\"team_9_cleaned.csv\", index=False)\n",
    "\n",
    "# Write df to a .txt file\n",
    "with open('team_9.txt', 'w') as f:\n",
    "    for index, row in df2.iterrows():\n",
    "        f.write(\n",
    "            f\"{row['transDate']},{row['category']},{row['amount']},{row['gender']},{row['dateOfBirth']},{row['distance_km']},{row['amount^2']}\\n\")\n",
    "\n",
    "#df2.head"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "388ce05011bb2dd4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading data test file & getting the np array of the predictions\n",
    "X_test = load_data(\"team_9.txt\", False)\n",
    "\n",
    "\"\"\"\n",
    "FOR WESTERN AI EXECS / JUDGES IF YOU WANNA RUN THE PREDICTOR WITHOUT WAITING FOR THE VALUES TO BE GENERATED UNCOMMENT THESE VARS\n",
    "\"\"\"\n",
    "\n",
    "# w = [-0.24387655, -0.23731882, -6.26273593, -0.3318153, -202.74208011, -6.25324663, -179.08671614]\n",
    "# b = 0.8975606836101722\n",
    "ans = predict(X_test, w, b, False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5228576deaddb4f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# New df that copies the original data and adds a isFraud col with values returned.\n",
    "df3 = pd.read_csv(\"team_9_og.csv\")\n",
    "df3[\"isFraud\"] = ans\n",
    "df3.to_csv(\"team_9.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bcd064e64260d6c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a753339ead3228b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
